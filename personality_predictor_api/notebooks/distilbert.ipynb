{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install --use-feature=2020-resolver --user torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "#%pip install --use-feature=2020-resolver --upgrade --user kagglehub transformers datasets evaluate accelerate typing_extensions tqdm\n",
    "#%pip install --use-feature=2020-resolver --user fastapi uvicorn pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import kagglehub\n",
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "def get_kaggle_df():\n",
    "    path = kagglehub.dataset_download(\"zeyadkhalid/mbti-personality-types-500-dataset\")\n",
    "    return pd.read_csv(os.path.join(path,'MBTI 500.csv'))\n",
    "\n",
    "def print_id2label():\n",
    "    df = get_kaggle_df()\n",
    "    l = list(df[\"type\"].unique())\n",
    "    print(f\"id2label = {{ {','.join([ str(k) + ':' + repr(t) for k,t in enumerate(l)])}}}\")\n",
    "    print(f\"label2id = {{ {','.join([ repr(t) + ':' +  str(k) for k,t in enumerate(l)])}}}\")\n",
    "\n",
    "def make_hf_ds():\n",
    "    df = get_kaggle_df()\n",
    "\n",
    "    def gen():\n",
    "        for i,v in df.iterrows():\n",
    "            yield {'text': v['posts'], 'label': label2id[v['type']]}\n",
    "\n",
    "    ds = Dataset.from_generator(gen)\n",
    "    ds_ = ds.train_test_split(test_size=0.1)\n",
    "    ds_.save_to_disk(os.path.join('..','data','mbti'))\n",
    "\n",
    "def load_ds():\n",
    "    return DatasetDict.load_from_disk(os.path.join('..','data','mbti'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print_id2label()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = { 0:'INTJ',1:'INTP',2:'ISFJ',3:'ISFP',4:'ISTJ',5:'ISTP',6:'ENFJ',7:'ENFP',8:'ENTJ',9:'ENTP',10:'ESFJ',11:'ESFP',12:'ESTJ',13:'ESTP',14:'INFJ',15:'INFP'}\n",
    "label2id = { 'INTJ':0,'INTP':1,'ISFJ':2,'ISFP':3,'ISTJ':4,'ISTP':5,'ENFJ':6,'ENFP':7,'ENTJ':8,'ENTP':9,'ESFJ':10,'ESFP':11,'ESTJ':12,'ESTP':13,'INFJ':14,'INFP':15}\n",
    "num_labels = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make_hf_ds() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_ds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'bite like ni type know thing think would accurate say difficuy verbalize reason think process visual spatial holistic rather verbal sequential like answer include low function well high one especially notice one fjs fps way many people near middle scale sometimes score wrong side way achieve balance help ferret type imo see si se ni ne fi fe ti te think problem people introvert social anxiet society make social anxiety hate bother everyone way society whole treat introvert vouch poeple introvert well social anxiety sometimes social situation always easy figure social anxiety make want leave tire introversion sure social anxious introvert way hate people simply direct r socialanxiety simple oh gosh get much live family reason marry job enjoy generally thing great get little sometimes wish understand good maybe stand offish right word think get past prickly outside want overwhelm person since tend thing know month really appreciate insight anything say ohhh goodness must hard feel feel right fe like sometimes still hug want sure look migraine thing seem like able make progress area life make lot easy work go school depend decide want keep talk keep listen sorry mean offence favorite quote life mean circa survive song must learn lose graciously accurate ahough really optimistic always look forward time problem communication trust go certain instance bearable others ok still possible infj also notice exist sub group claim need acknowledgement others show importance something get dress everytime leave house worry someone think le claim one understand yet walk around show mask world sound bite like low self esteem narcissism tbh point view least think highly really really worry others feel want validation others struggle validate want tell good hard time believe show mask world scar open get shoot feel even bad understand plus pretty common trait infjs guard might narcissism could wrong know specific situation whatever think talk infjs undoubtedly complicate seem first glance course say every infj sting probably time favorite like offspring favorite tend come go listen playlist work look forward feel need new music curious whether fellow infj would lead new favorite cannot stand small talk personally mostly time energy precious like spend understand people want invite life good oh hey da weather like try derail attempt small talk actual conversation go anywhere get bore person conversation uncomfortably move something else seem busy flee different room work person leave know think preoccupy idea capable lenhy enjoyable conversation help make oneself interest small talk conversation mother really listen well become frustrate get upset try explain attitude come get upset listen respect feel course really listen wait turn speak soon finish sentence declare respect feel explain understand say repeat say back use different word still listen say respond say understand want discussion anyways want everything would good say frustrate would understatement pro tip anybody read ever move back parent get ready rocky road fortunately consider silly theory thing really matter life relationship people million deathbed testimonial teach u look back live wish wed work hard maintain inbox zero finish',\n",
       " 'label': 14}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True)\n",
    "\n",
    "tokenized_ds = ds.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert/distilbert-base-uncased\", num_labels=num_labels, id2label=id2label, label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 2060'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a41a6bafc7c049b3bfe7c5f707450802",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5967 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ruiba\\AppData\\Roaming\\Python\\Python38\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:403: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.5981, 'grad_norm': 13.78458023071289, 'learning_rate': 1.8324115971174795e-05, 'epoch': 0.08}\n",
      "{'loss': 0.9328, 'grad_norm': 9.150552749633789, 'learning_rate': 1.664823194234959e-05, 'epoch': 0.17}\n",
      "{'loss': 0.8454, 'grad_norm': 9.421222686767578, 'learning_rate': 1.4972347913524386e-05, 'epoch': 0.25}\n",
      "{'loss': 0.7677, 'grad_norm': 11.670267105102539, 'learning_rate': 1.329646388469918e-05, 'epoch': 0.34}\n",
      "{'loss': 0.7372, 'grad_norm': 7.803522109985352, 'learning_rate': 1.1620579855873975e-05, 'epoch': 0.42}\n",
      "{'loss': 0.6839, 'grad_norm': 11.943435668945312, 'learning_rate': 9.94469582704877e-06, 'epoch': 0.5}\n",
      "{'loss': 0.6624, 'grad_norm': 6.102105617523193, 'learning_rate': 8.268811798223564e-06, 'epoch': 0.59}\n",
      "{'loss': 0.64, 'grad_norm': 12.100564002990723, 'learning_rate': 6.592927769398358e-06, 'epoch': 0.67}\n",
      "{'loss': 0.5919, 'grad_norm': 6.732193470001221, 'learning_rate': 4.917043740573153e-06, 'epoch': 0.75}\n",
      "{'loss': 0.6071, 'grad_norm': 9.361861228942871, 'learning_rate': 3.241159711747947e-06, 'epoch': 0.84}\n",
      "{'loss': 0.6088, 'grad_norm': 7.519313812255859, 'learning_rate': 1.565275682922742e-06, 'epoch': 0.92}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf984ca2fe424efe93a05809a8360931",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/663 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5660577416419983, 'eval_accuracy': 0.8261525407749599, 'eval_runtime': 200.8802, 'eval_samples_per_second': 52.803, 'eval_steps_per_second': 3.3, 'epoch': 1.0}\n",
      "{'train_runtime': 6245.074, 'train_samples_per_second': 15.286, 'train_steps_per_second': 0.955, 'train_loss': 0.7746280895838571, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5967, training_loss=0.7746280895838571, metrics={'train_runtime': 6245.074, 'train_samples_per_second': 15.286, 'train_steps_per_second': 0.955, 'total_flos': 1.264849503879168e+16, 'train_loss': 0.7746280895838571, 'epoch': 1.0})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"../models/my_mbti\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_ds[\"train\"],\n",
    "    eval_dataset=tokenized_ds[\"test\"],\n",
    "    processing_class=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline(\"text-classification\", model=\"../models/my_mbti/checkpoint-5967\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'INFJ', 'score': 0.13813404738903046},\n",
       " {'label': 'INFJ', 'score': 0.13813404738903046}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier([\"I am a very happy person\", \"I am a very happy person\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a6400dbd9cd42e0b6f30c57b67f1f7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token has not been saved to git credential helper.\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5717434d7a624186b57d173af0ccfe93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training_args.bin:   0%|          | 0.00/5.24k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ad850d68c204f2ca6d264a8f992d6f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c043712043784e69a5d234ff40beb13e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/rbarreiro/my_mbti/commit/fed2d30358c31a8498d0528072127d2cd1765e0e', commit_message='End of training', commit_description='', oid='fed2d30358c31a8498d0528072127d2cd1765e0e', pr_url=None, repo_url=RepoUrl('https://huggingface.co/rbarreiro/my_mbti', endpoint='https://huggingface.co', repo_type='model', repo_id='rbarreiro/my_mbti'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline;classifier = pipeline(\"text-classification\", model=\"rbarreiro/my_mbti\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
